{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633e6100",
   "metadata": {},
   "source": [
    "## 1. Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a13ebe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "# from prettytable import PrettyTable\n",
    "# from gensim.models import KeyedVectors\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c3e289",
   "metadata": {},
   "source": [
    "## 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d16a983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizing_to_word2vec(X, word2vec_model):\n",
    "    # vectorizing comment in data using word2vec embeddings\n",
    "    start = datetime.now()\n",
    "    word2vec_data = []\n",
    "    for comment in X:\n",
    "        vector = np.zeros(300)\n",
    "        for word in comment.split():\n",
    "            if word in word2vec_model:     \n",
    "                vec = word2vec_model[word]\n",
    "            else:\n",
    "                vec = np.zeros(300)\n",
    "            vector += vec\n",
    "        word2vec_data.append(vector)\n",
    "    word2vec_data = np.array(word2vec_data)\n",
    "    print(\"Time taken: \", datetime.now() - start)\n",
    "    return word2vec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "34395cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizing_to_glove(X, glove_model):\n",
    "    # vectorizing comment in data using glove embeddings\n",
    "    start = datetime.now()\n",
    "    glove_data = []\n",
    "    for comment in X:\n",
    "        vector = np.zeros(300)\n",
    "        for word in comment.split():\n",
    "            if word in glove_model.keys():\n",
    "                vector += glove_model[word]\n",
    "        glove_data.append(vector)\n",
    "    glove_data = np.array(glove_data)\n",
    "    print(\"Time taken: \", datetime.now() - start)\n",
    "    return glove_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1b031e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizing_to_fasttext(X, fasttext_model):\n",
    "    # vectorizing comment in data using fast embeddings\n",
    "    start = datetime.now()\n",
    "    fasttext_data = []\n",
    "    for comment in X:\n",
    "        vector = np.zeros(300)\n",
    "        for word in comment.split():\n",
    "            vec = fasttext_model.get_word_vector(word)\n",
    "            vector += vec\n",
    "        fasttext_data.append(vector)\n",
    "    fasttext_data = np.array(fasttext_data)\n",
    "    print(\"Time taken: \", datetime.now() - start)\n",
    "    return fasttext_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a9c04ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings(save_folder, file_name, embeddings):\n",
    "    try:\n",
    "        SAVE_PATH = os.path.join(save_folder, file_name)\n",
    "        with open(SAVE_PATH, 'wb') as f:\n",
    "            pickle.dump(embeddings, f)\n",
    "        print(f\"Successfully saved at : {SAVE_PATH}\")\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7260dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(save_folder, file_name):\n",
    "    try:\n",
    "        SAVE_PATH = os.path.join(save_folder, file_name)\n",
    "        with open(SAVE_PATH, 'rb') as f:\n",
    "            word2vec_data = pickle.load(f)\n",
    "        print(f\"Loaded from : {SAVE_PATH}\")\n",
    "        return word2vec_data\n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "30590f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fab633",
   "metadata": {},
   "source": [
    "## 3. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9d4ae6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data\"\n",
    "SAVE_PATH = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "16ef7b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>worldcom ex boss launches defence lawyers defe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>bbc poll indicates economic gloom citizens maj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "      <td>lifestyle governs mobile choice faster better ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "      <td>enron bosses payout eighteen former enron dire...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category  \\\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business   \n",
       "1        154  german business confidence slides german busin...  business   \n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business   \n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech   \n",
       "4        917  enron bosses in $168m payout eighteen former e...  business   \n",
       "\n",
       "                                          clean_text  Label  \n",
       "0  worldcom ex boss launches defence lawyers defe...      0  \n",
       "1  german business confidence slides german busin...      0  \n",
       "2  bbc poll indicates economic gloom citizens maj...      0  \n",
       "3  lifestyle governs mobile choice faster better ...      1  \n",
       "4  enron bosses payout eighteen former enron dire...      0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_PATH, \"train_clean_data.csv\"))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c9c7758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['ArticleId', 'Label','Text','Category'], axis=1)\n",
    "y = train_df['Label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42254c2e",
   "metadata": {},
   "source": [
    "## 4. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eff907c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_k_fold_cv_f1(model, X, y, n_splits=5, shuffle=True, random_state=98):\n",
    "    \"\"\"\n",
    "    Perform Stratified K-Fold Cross Validation and return the average F1 score.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The machine learning model to evaluate.\n",
    "    - X: The feature matrix (data).\n",
    "    - y: The target vector (labels).\n",
    "    - n_splits: Number of splits/folds for cross-validation (default is 5).\n",
    "    - shuffle: Whether to shuffle the data before splitting (default is True).\n",
    "    - random_state: Seed for random number generator to ensure reproducibility.\n",
    "    \n",
    "    Returns:\n",
    "    - avg_f1: The average F1 score across all folds.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize StratifiedKFold with specified number of splits and options\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "    \n",
    "    f1_scores = []  # List to store F1 score for each fold\n",
    "    \n",
    "    # Split the data into train and test sets for each fold\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Train the model on the training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate and store the F1 score for this fold\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    # Calculate the average F1 score across all folds\n",
    "    avg_f1 = sum(f1_scores) / len(f1_scores)\n",
    "    avg_std_f1 = np.std(f1_scores)\n",
    "    return avg_f1, avg_std_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e7801b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_performance(model, X, y, n_splits=5, shuffle=True, random_state=98):\n",
    "    avg_f1, std_f1 = stratified_k_fold_cv_f1(model, X, y, n_splits, shuffle, random_state)\n",
    "    print(f\"Train Avg F1 Score: {avg_f1} Std: {std_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8e513",
   "metadata": {},
   "source": [
    "## 5. Word2Vec Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "88986072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained word2vec embeddings\n",
    "# WORK2VEC_EMBEDDING_PATH = \"/kaggle/input/google-word2vec/GoogleNews-vectors-negative300.bin\"\n",
    "# word2vec_model = KeyedVectors.load_word2vec_format(WORK2VEC_EMBEDDING_PATH, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9ad93",
   "metadata": {},
   "source": [
    "### 5.1. Vectorizing text using Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e599f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_data = vectorizing_to_word2vec(X['clean_text'], word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "07ce2e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_embeddings(SAVE_PATH, 'word2vec_embeddings.pkl', word2vec_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4192705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f9f07",
   "metadata": {},
   "source": [
    "### 5.2. Loading Saved word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7115937d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from : data/word2vec_embeddings.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1490, 300)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_data = load_embeddings(SAVE_PATH, 'word2vec_embeddings.pkl')\n",
    "word2vec_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1e2f4",
   "metadata": {},
   "source": [
    "### 5.3 Scaling Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "97fa504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shpe: (1490, 300)\n",
      "Data Shpe: (1490, 300)\n"
     ]
    }
   ],
   "source": [
    "# preprocessing data to standardize data with mean 0\n",
    "scaler = StandardScaler()\n",
    "word2vec_std_scaled = scaler.fit_transform(word2vec_data)\n",
    "print('Data Shpe:', word2vec_std_scaled.shape)\n",
    "\n",
    "# preprocessing data to convert to range 0-1\n",
    "scaler = MinMaxScaler()\n",
    "word2vec_minmax_scaled = scaler.fit_transform(word2vec_data)\n",
    "print('Data Shpe:', word2vec_minmax_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4f95942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"/Users/rahulshelke/Documents/Data-Science/Data-Science-Projects/bbc-news-sorting/notebooks/mlruns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d3150a",
   "metadata": {},
   "source": [
    "### 5.4 Logistic Regression on Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "11b28d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.77 µs\n",
      "Logged Logistic Regression model with avg f1 score: 0.9684976075457431\n",
      "Logged Logistic Regression model with avg f1 std: 0.006185096595692143\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Start an experiment (if not already created)\n",
    "experiment_name = \"Word2Vec_Embeddings\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "model_name = \"Logistic Regression\"\n",
    "model_save_name = \"logistic_regression_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = LogisticRegression(max_iter=2000)\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, word2vec_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde956c8",
   "metadata": {},
   "source": [
    "### 5.5 Naive Bayes on word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "86c88bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.15 µs\n",
      "Logged Naive Bayes model with avg f1 score: 0.8390521476927397\n",
      "Logged Naive Bayes model with avg f1 std: 0.027083752273604995\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Naive Bayes\"\n",
    "model_save_name = \"naive_bayes_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, word2vec_minmax_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7388a",
   "metadata": {},
   "source": [
    "### 5.6 SVC on word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bce5eedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.86 µs\n",
      "Logged SVC model with avg f1 score: 0.9495994624826165\n",
      "Logged SVC model with avg f1 std: 0.012994664045244868\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"SVC\"\n",
    "model_save_name = \"svc_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = SVC()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, word2vec_minmax_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4572cfe7",
   "metadata": {},
   "source": [
    "### 5.7 Random Forest on word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ee4a685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n",
      "Logged Random Forest model with avg f1 score: 0.9516302673406869\n",
      "Logged Random Forest model with avg f1 std: 0.015207650281093953\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Random Forest\"\n",
    "model_save_name = \"random_forest_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = RandomForestClassifier()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, word2vec_minmax_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7a7169",
   "metadata": {},
   "source": [
    "### 5.8 Gradient Boost on word2vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c55e9dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1e+03 ns, total: 2 µs\n",
      "Wall time: 1.67 µs\n",
      "Logged Gradient Boost model with avg f1 score: 0.9543309475920368\n",
      "Logged Gradient Boost model with avg f1 std: 0.01457738321229346\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Gradient Boost\"\n",
    "model_save_name = \"gradient_boosting_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = GradientBoostingClassifier()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, word2vec_minmax_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1ab53",
   "metadata": {},
   "source": [
    "## 6. Glove Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "77e84a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOVE_EMBEDDING_PATH = \"/kaggle/input/glove6b300dtxt/glove.6B.300d.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22631749",
   "metadata": {},
   "source": [
    "### 6.1. Vectorizing text using glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7c8ca09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pre-trained glove embeddings\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r', encoding=\"utf8\")\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b514feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_model = loadGloveModel(GLOVE_EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "46a16335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_data = vectorizing_to_glove(X['clean_text'], glove_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4f648a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of train data embeddings\n",
    "# glove_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8bc77f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving embeddings for data column comment\n",
    "# save_embeddings(SAVE_PATH, \"glove_embeddings.pkl\", glove_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398add4b",
   "metadata": {},
   "source": [
    "### 6.2 Loading saved glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4bbb8b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from : data/glove_embeddings.pkl\n"
     ]
    }
   ],
   "source": [
    "# saving embeddings for data column comment\n",
    "glove_data = load_embeddings(SAVE_PATH, \"glove_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1760b",
   "metadata": {},
   "source": [
    "### 6.3 Scaling on Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bd9c3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing data to standardize data with mean 0\n",
    "std_scaler = StandardScaler()\n",
    "glove_std_scaled = std_scaler.fit_transform(glove_data)\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "glove_minmax_scaled = minmax_scaler.fit_transform(glove_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cbb98",
   "metadata": {},
   "source": [
    "### 6.4 Logistic Regression on Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a0186d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/27 01:20:49 INFO mlflow.tracking.fluent: Experiment with name 'GloVe_Embeddings' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 8.11 µs\n",
      "Logged Logistic Regression model with avg f1 score: 0.9718482530789798\n",
      "Logged Logistic Regression model with avg f1 std: 0.006860856964094403\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Start an experiment (if not already created)\n",
    "experiment_name = \"GloVe_Embeddings\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "model_name = \"Logistic Regression\"\n",
    "model_save_name = \"logistic_regression_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = LogisticRegression(max_iter=2000)\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, glove_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2710a65",
   "metadata": {},
   "source": [
    "### 6.5 Naive Bayes on glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "25b86e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 3 µs, total: 7 µs\n",
      "Wall time: 10 µs\n",
      "Logged Naive Bayes model with avg f1 score: 0.9155249265919974\n",
      "Logged Naive Bayes model with avg f1 std: 0.014480953723875412\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Naive Bayes\"\n",
    "model_save_name = \"naive_bayes_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, glove_minmax_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01d366",
   "metadata": {},
   "source": [
    "### 6.6 SVC on glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "efbc6d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.62 µs\n",
      "Logged SVC model with avg f1 score: 0.9678993850593406\n",
      "Logged SVC model with avg f1 std: 0.006180751324692117\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"SVC\"\n",
    "model_save_name = \"svc_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = SVC()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, glove_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6840ae6",
   "metadata": {},
   "source": [
    "### 6.7 Random Forest on glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6581dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 3.1 µs\n",
      "Logged Random Forest model with avg f1 score: 0.9576199020561529\n",
      "Logged Random Forest model with avg f1 std: 0.008164490390919038\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Random Forest\"\n",
    "model_save_name = \"random_forest_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = RandomForestClassifier()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, glove_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fefdc80",
   "metadata": {},
   "source": [
    "### 6.8 Gradient Boost on glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "579b3604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.05 µs\n",
      "Logged Gradient Boost model with avg f1 score: 0.955777765182425\n",
      "Logged Gradient Boost model with avg f1 std: 0.006830385211894745\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Gradient Boost\"\n",
    "model_save_name = \"gradient_boosting_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = GradientBoostingClassifier()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, glove_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e97de1",
   "metadata": {},
   "source": [
    "## 7. FastText Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8ddce242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FASTTEXT_EMBEDDING_PATH = \"/kaggle/input/fasttext-english-300/cc.en.300.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "496cad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fasttext.util\n",
    "# fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "# ft = fasttext.load_model(FASTTEXT_EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4dfe0a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft.get_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923fcc77",
   "metadata": {},
   "source": [
    "### 7.1. Vectorizing text using fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "41ccb891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext_data = vectorizing_to_fasttext(X['clean_text'], ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "54ae05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_embeddings(SAVE_PATH, 'fasttext_data.pkl', fasttext_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "091ff882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b1c16",
   "metadata": {},
   "source": [
    "### 7.2. Loading Saved fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fe36eac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from : data/fasttext_data.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1490, 300)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_data = load_embeddings(SAVE_PATH, 'fasttext_data.pkl')\n",
    "fasttext_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd57b9c",
   "metadata": {},
   "source": [
    "### 7.3 Scaling fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6483c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing data to convert to range 0-1\n",
    "scaler = StandardScaler()\n",
    "fasttext_std_scaled = scaler.fit_transform(fasttext_data)\n",
    "\n",
    "# preprocessing data to convert to range 0-1\n",
    "scaler = MinMaxScaler()\n",
    "fasttext_minmax_scaled = scaler.fit_transform(fasttext_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f0dbeb",
   "metadata": {},
   "source": [
    "### 7.4 Logistic Regression on fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0301b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/27 01:24:46 INFO mlflow.tracking.fluent: Experiment with name 'FastText_Embeddings' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 12.9 µs\n",
      "Logged Logistic Regression model with avg f1 score: 0.9624145089184226\n",
      "Logged Logistic Regression model with avg f1 std: 0.011343718947799557\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# Start an experiment (if not already created)\n",
    "experiment_name = \"FastText_Embeddings\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "model_name = \"Logistic Regression\"\n",
    "model_save_name = \"logistic_regression_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = LogisticRegression(max_iter=2000)\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, fasttext_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcc716",
   "metadata": {},
   "source": [
    "### 7.5 Naive Bayes on fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1063bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 4.77 µs\n",
      "Logged Naive Bayes model with avg f1 score: 0.7509317153832529\n",
      "Logged Naive Bayes model with avg f1 std: 0.023732069110960975\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Naive Bayes\"\n",
    "model_save_name = \"naive_bayes_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = MultinomialNB()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, fasttext_minmax_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94342a7f",
   "metadata": {},
   "source": [
    "### 7.6 SVC on fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "46d29fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 0 ns, total: 1 µs\n",
      "Wall time: 4.05 µs\n",
      "Logged SVC model with avg f1 score: 0.9599365089808403\n",
      "Logged SVC model with avg f1 std: 0.009565816728661237\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"SVC\"\n",
    "model_save_name = \"svc_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = SVC()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, fasttext_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30cf003",
   "metadata": {},
   "source": [
    "### 7.7 Random Forest on fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d0a0cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.15 µs\n",
      "Logged Random Forest model with avg f1 score: 0.9510224096687907\n",
      "Logged Random Forest model with avg f1 std: 0.009197314985749239\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Random Forest\"\n",
    "model_save_name = \"random_forest_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = RandomForestClassifier()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, fasttext_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ee1ea",
   "metadata": {},
   "source": [
    "### 7.8 Gradient Boost on fasttext embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9abacd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 1 µs, total: 2 µs\n",
      "Wall time: 1.91 µs\n",
      "Logged Gradient Boost model with avg f1 score: 0.9463989861852939\n",
      "Logged Gradient Boost model with avg f1 std: 0.00631698464348885\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_name = \"Gradient Boost\"\n",
    "model_save_name = \"gradient_boosting_model\"\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=f\"{experiment_name} + {model_name}\"):\n",
    "\n",
    "    # initializing model\n",
    "    classifier = GradientBoostingClassifier()\n",
    "\n",
    "    # cross validation\n",
    "    avg_f1_score, avg_f1_std = stratified_k_fold_cv_f1(classifier, fasttext_std_scaled, y)\n",
    "\n",
    "    # Log metrics (e.g., f1 score, precision, recall, F1-score)\n",
    "    mlflow.log_metric(\"avg f1 score\", avg_f1_score)\n",
    "    mlflow.log_metric(\"avg f1 std\", avg_f1_std)\n",
    "    mlflow.log_param(\"models\", model_name)\n",
    "\n",
    "    print(f\"Logged {model_name} model with avg f1 score: {avg_f1_score}\")\n",
    "    print(f\"Logged {model_name} model with avg f1 std: {avg_f1_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d06e73",
   "metadata": {},
   "source": [
    "## 8. Final Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f4433",
   "metadata": {},
   "source": [
    "- Glove with Logistic Regression: **97%** f1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
